{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOG3pXs8TxLY"
      },
      "source": [
        "# Lab 4: TableGPT\n",
        "\n",
        "In this lab, we'll discover the power of code generation models through TableGPT2. The aim is to see how the model can be used in data analysis.\n",
        "\n",
        "First of all, the notebook is divided into X sections: 0. Installation: This section is dedicated to module installation, model loading and data loading.\n",
        "\n",
        "1. Guided introduction: Together, we'll discover how to use and evaluate TableGPT2.\n",
        "2. More questions: You'll need to add at least one new question type to our simple evaluation system.\n",
        "3. More data sets: You'll need to implement a question with multiple datasets.\n",
        "\n",
        "IMPORTANT:\n",
        "\n",
        "- You must work in pairs. You must submit **ONLY ONE NOTEBOOK** for each pair.\n",
        "- Do not share your work with other pairs.\n",
        "- You should not use Copilot, ChatGPT or similar tools. At the very least, remove the prompt ...\n",
        "- <font color='red'>All the things you need to do are indicated in red.</font>\n",
        "\n",
        "<font color='red'>**FIRST QUESTION:** What are the specificty of the TableGPT2 model?</font> https://huggingface.co/tablegpt/TableGPT2-7B\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az4ycBgrXuDU"
      },
      "source": [
        "## 0. Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "MlTjE4nDH05G"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers datasets bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "TYDBffMEX5Pw"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    GenerationConfig,\n",
        ")\n",
        "\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "DU7OdU7mzyfN"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00ab17218fd544bab156940d206af296",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(152064, 3584)\n",
              "    (layers): ModuleList(\n",
              "      (0-27): 28 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_name = \"tablegpt/TableGPT2-7B\"\n",
        "\n",
        "# We want to use 4bit quantization to save memory\n",
        "quantization_config = BitsAndBytesConfig(load_in_8bit=False, load_in_4bit=True)\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm_name, padding_side=\"left\")\n",
        "# Prevent some transformers specific issues.\n",
        "tokenizer.use_default_system_prompt = False\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Load LLM.\n",
        "llm = AutoModelForCausalLM.from_pretrained(\n",
        "    llm_name,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"cuda\",  # load all the model layers on GPU 0\n",
        "    torch_dtype=torch.bfloat16,  # float precision\n",
        ")\n",
        "# Set LLM on eval mode.\n",
        "llm.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "HAciK5cIWxgb"
      },
      "outputs": [],
      "source": [
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    # do_sample=True,\n",
        "    # temperature=.7,\n",
        "    # top_p=.8,\n",
        "    # top_k=20,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ME-E7zK-zZwU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 712 entries, 0 to 890\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  712 non-null    int64  \n",
            " 1   Survived     712 non-null    int64  \n",
            " 2   Pclass       712 non-null    int64  \n",
            " 3   Name         712 non-null    object \n",
            " 4   Sex          712 non-null    object \n",
            " 5   Age          712 non-null    float64\n",
            " 6   SibSp        712 non-null    int64  \n",
            " 7   Parch        712 non-null    int64  \n",
            " 8   Ticket       712 non-null    object \n",
            " 9   Fare         712 non-null    float64\n",
            " 10  Embarked     712 non-null    object \n",
            "dtypes: float64(2), int64(5), object(4)\n",
            "memory usage: 66.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"hf://datasets/phihung/titanic/train.csv\")\n",
        "df = df.drop(\"Cabin\", axis=1).dropna()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPxFK_SbYIGf"
      },
      "source": [
        "## 1.1 Guided Introduction: The Model.\n",
        "\n",
        "Below there is an example of a prompt that could be used with TableGPT2.\n",
        "\n",
        "```\n",
        "Given access to several pandas dataframes, write the Python code to answer the user's question.\n",
        "The answer should be store in a variable named \"output\".\n",
        "\n",
        "/*\n",
        "\"df.head(5).to_string(index=False)\" as follows:\n",
        " PassengerId  Survived  Pclass                                                Name    Sex  Age  SibSp  Parch           Ticket    Fare Embarked\n",
        "           1         0       3                             Braund, Mr. Owen Harris   male 22.0      1      0        A/5 21171  7.2500        S\n",
        "           2         1       1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38.0      1      0         PC 17599 71.2833        C\n",
        "           3         1       3                              Heikkinen, Miss. Laina female 26.0      0      0 STON/O2. 3101282  7.9250        S\n",
        "           4         1       1        Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0      1      0           113803 53.1000        S\n",
        "           5         0       3                            Allen, Mr. William Henry   male 35.0      0      0           373450  8.0500        S\n",
        "*/\n",
        "\n",
        "Question: How many child survive? (under 18)\n",
        "```\n",
        "\n",
        "The prompt is divided in 3 parts:\n",
        "\n",
        "1. The global instruction wich is to write python that could answer a question on a specific dataset.\n",
        "2. The header of the given dataset: 5 first lines of titanic dataset.\n",
        "3. The question to answer: \"How many child survive? (under 18)\n",
        "\n",
        "First, we will implement a function that generate an answer for this prompt.\n",
        "\n",
        "<font color='red'>TODO: Fill in the `generate_answer` function following the comments inside.</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "pvUClWNx1jEj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given access to several pandas dataframes, write the Python code to answer the user's question.\n",
            "The answer should be store in a variable named \"output\".\n",
            "\n",
            "/*\n",
            "\"df.head(5).to_string(index=False)\" as follows:\n",
            " PassengerId  Survived  Pclass                                                Name    Sex  Age  SibSp  Parch           Ticket    Fare Embarked\n",
            "           1         0       3                             Braund, Mr. Owen Harris   male 22.0      1      0        A/5 21171  7.2500        S\n",
            "           2         1       1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38.0      1      0         PC 17599 71.2833        C\n",
            "           3         1       3                              Heikkinen, Miss. Laina female 26.0      0      0 STON/O2. 3101282  7.9250        S\n",
            "           4         1       1        Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0      1      0           113803 53.1000        S\n",
            "           5         0       3                            Allen, Mr. William Henry   male 35.0      0      0           373450  8.0500        S\n",
            "*/\n",
            "\n",
            "Question: How many child survive? (under 18)\n",
            "\n",
            "\n",
            "*****\n",
            "\n",
            "Python code:\n",
            "```python\n",
            "# Filter the dataframe to include only passengers under the age of 18\n",
            "children = df[df['Age'] < 18]\n",
            "\n",
            "# Count the number of children who survived\n",
            "child_survivors = children[children['Survived'] == 1]\n",
            "\n",
            "# Save the answer in the variable 'output'\n",
            "output = len(child_survivors)\n",
            "print(output)\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "example_prompt_template = \"\"\"Given access to several pandas dataframes, write the Python code to answer the user's question.\n",
        "The answer should be store in a variable named \"output\".\n",
        "\n",
        "/*\n",
        "\"{var_name}.head(5).to_string(index=False)\" as follows:\n",
        "{df_info}\n",
        "*/\n",
        "\n",
        "Question: {user_question}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_answer(prompt, llm=llm, generation_config=generation_config):\n",
        "    # Create turns with the given prompt.\n",
        "    chat = [\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        "\n",
        "    # Apply template with the tokenizer. Be careful to return pt tensors on the same device than `llm`.\n",
        "    chat_encoded = tokenizer.apply_chat_template(chat, return_tensors=\"pt\").to(\n",
        "        llm.device\n",
        "    )\n",
        "\n",
        "    # Generate with llm using the given generation config.\n",
        "    llm_outputs_ids = llm.generate(\n",
        "        input_ids=chat_encoded,\n",
        "        generation_config=generation_config,\n",
        "    )[0]\n",
        "\n",
        "    # Decode and select the answer to return.\n",
        "    answer = tokenizer.decode(\n",
        "        llm_outputs_ids[chat_encoded.size(1) :], skip_special_tokens=True\n",
        "    )\n",
        "    return answer\n",
        "\n",
        "\n",
        "prompt = example_prompt_template.format(\n",
        "    var_name=\"df\",\n",
        "    df_info=df.head(5).to_string(index=False),\n",
        "    user_question=\"How many child survive? (under 18)\",\n",
        ")\n",
        "\n",
        "answer = generate_answer(prompt)\n",
        "\n",
        "print(prompt)\n",
        "print(\"\\n*****\\n\")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Nt90EerdwBN"
      },
      "source": [
        "## 1.2 Guided Introduction: The Answer.\n",
        "\n",
        "As you can see, the model answer with some generated code.\n",
        "\n",
        "````\n",
        "Python code:\n",
        "```python\n",
        "# Filter the dataframe to include only passengers under the age of 18\n",
        "children = df[df['Age'] < 18]\n",
        "\n",
        "# Count the number of children who survived\n",
        "child_survivors = children[children['Survived'] == 1]\n",
        "\n",
        "# Save the answer in the variable output\n",
        "output = len(child_survivors)\n",
        "````\n",
        "\n",
        "So we will need to execute it, but there is some difficulty:\n",
        "\n",
        "1. Sometime, the llm answer with \\`\\`\\`python ... \\`\\`\\`, sometime the llm answer directly with the code. We need to handle both cases.\n",
        "2. We need to recover the variable output from the execution.\n",
        "3. We need to evaluate single value and list of values.\n",
        "\n",
        "First, we will implement a function that generate an answer for this prompt.\n",
        "\n",
        "<font color='red'>TODO: Fill in the `exec_answer` function following the comments inside.</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "z_hwvxSGMSlo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "import re, sys, os\n",
        "\n",
        "\n",
        "def exec_answer(answer, gold):\n",
        "    # Extract the code from the answer. Be careful, the code is now always in ``` ```.\n",
        "    if \"```\" in answer:\n",
        "        code = re.search(r\"```python\\n(.*?)\\n```\", answer, re.DOTALL)\n",
        "        code = code.group(1)\n",
        "    else:\n",
        "        code = answer\n",
        "\n",
        "    # Execute the code, https://docs.python.org/3/library/functions.html#exec\n",
        "    # if the code work: Return True or False based on output == gold (be careful to handle iterable !)\n",
        "    # if the code don't work return False.\n",
        "\n",
        "    original_stdout = sys.stdout  # suppress output from exec\n",
        "    try:\n",
        "        sys.stdout = open(os.devnull, \"w\")\n",
        "        context = {\"df\": df}\n",
        "        exec(code, context)\n",
        "        output = next(reversed(context.values()))\n",
        "\n",
        "        if isinstance(output, pd.DataFrame) or isinstance(output, pd.Series):\n",
        "            raise Exception(\"Output is a DataFrame or Series, please return a scalar.\")\n",
        "\n",
        "        sys.stdout = original_stdout\n",
        "        return output == gold\n",
        "    except Exception as e:\n",
        "        sys.stdout = original_stdout\n",
        "        print(e)\n",
        "        return False\n",
        "\n",
        "\n",
        "print(exec_answer(answer, 61))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1TrmGcQIEeI"
      },
      "source": [
        "## 1.3 Guided Introduction: The Question.\n",
        "\n",
        "Now we want to automatically generate questions to evaluate the performance of our model. There are benchmarks on this subject, but here we want to practice code by generating the questions ourselves.\n",
        "\n",
        "We will generate some basic filter questions.\n",
        "\n",
        "<font color='red'>TODO: Fill in the `generate_filter_question` function following the comments inside.</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'question': \"What is the number of rows where the value in the column 'Embarked' is 'S' and the value in the column 'PassengerId' is '351'?\",\n",
              "  'answer': 1}]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def generate_random_question(generate_function, df, k, seed=42):\n",
        "    random.seed(seed)\n",
        "    questions = []\n",
        "    for _ in tqdm(range(k)):\n",
        "        question = generate_function(df)\n",
        "        questions.append(question)\n",
        "    return questions\n",
        "\n",
        "\n",
        "def generate_filter_question(df):\n",
        "    # Get a random target column and a random filter column (be careful they should be different)\n",
        "    # Get a random filter value inside the filer column. Avoid NaN values.\n",
        "    target_col = random.choice(df.columns)\n",
        "    target_val = random.choice(df[target_col].dropna().unique())\n",
        "    filter_col = random.choice([col for col in df.columns if col != target_col])\n",
        "    filter_val = random.choice(df[filter_col].dropna().unique())\n",
        "    # operation = random.choice(numerical_ops)\n",
        "\n",
        "    # Create a question template that take a target column, a filter column and a filter value\n",
        "    # WE ARE ALSO ADDING A TARGET VALUE, OTHERWISE THE ANSWER IS IMPOSSIBLE TO COMPUTE\n",
        "    template = (\n",
        "        \"Generate a question based on this tabular dataset:\\n\"\n",
        "        \"{df_info}\\n\"\n",
        "        \"The question should be about the number of rows where the value in the column '{target_col}' is '{target_val}' \"\n",
        "        \"and the value in the column '{filter_col}' is '{filter_val}'.\"\n",
        "    )\n",
        "\n",
        "    content = template.format(\n",
        "        df_info=df.head(5).to_string(index=False),\n",
        "        target_col=target_col,\n",
        "        target_val=target_val,\n",
        "        filter_col=filter_col,\n",
        "        filter_val=filter_val,\n",
        "    )\n",
        "\n",
        "    chat = [\n",
        "        {\"role\": \"user\", \"content\": content},\n",
        "    ]\n",
        "    chat_encoded = tokenizer.apply_chat_template(chat, return_tensors=\"pt\").to(\n",
        "        llm.device\n",
        "    )\n",
        "\n",
        "    llm_outputs_ids = llm.generate(\n",
        "        input_ids=chat_encoded,\n",
        "        generation_config=generation_config,\n",
        "    )[0]\n",
        "    question = tokenizer.decode(\n",
        "        llm_outputs_ids[chat_encoded.size(1) :], skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    # Compute the correct answer for the given target column, filter column and filter value.\n",
        "    correct_answer = df[\n",
        "        (df[target_col] == target_val) & (df[filter_col] == filter_val)\n",
        "    ].shape[0]\n",
        "\n",
        "    # print(df[(df[target_col] == target_val) & (df[filter_col] == filter_val)])\n",
        "    # print(df[(df[target_col] == target_val) & (df[filter_col] == filter_val)].shape)\n",
        "\n",
        "    # return formatted question and associated answer in a dict {\"question\":[question], \"answer\":[answer]}\n",
        "    return {\"question\": question, \"answer\": correct_answer}\n",
        "\n",
        "\n",
        "generate_random_question(generate_filter_question, df, k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "il2vCMHRJ74t"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import operator\n",
        "\n",
        "\n",
        "# def generate_random_question(generate_function, df, k=1, seed=42):\n",
        "#     #random.seed(seed)\n",
        "#     return [generate_function(df) for _ in range(k)]\n",
        "\n",
        "\n",
        "# def generate_filter_question(df):\n",
        "#     categorical_columns = [\"Sex\", \"Pclass\", \"Embarked\", \"Survived\"]\n",
        "#     numerical_columns = [\"Age\", \"Fare\", \"SibSp\", \"Parch\"]\n",
        "#     numerical_ops = [\"<\", \">\", \"==\", \"!=\", \"<=\", \">=\"]\n",
        "#     operators = {\n",
        "#         \"<\": operator.lt,\n",
        "#         \">\": operator.gt,\n",
        "#         \"==\": operator.eq,\n",
        "#         \"!=\": operator.ne,\n",
        "#         \"<=\": operator.le,\n",
        "#         \">=\": operator.ge,\n",
        "#     }\n",
        "\n",
        "#     # Get a random target column and a random filter column (be careful they should be different)\n",
        "#     # Get a random filter value inside the filter column. Avoid NaN values.\n",
        "#     filter_column = random.choice(categorical_columns + numerical_columns)\n",
        "\n",
        "#     if filter_column in categorical_columns:  # Categorical column\n",
        "#         filter_value = random.choice(df[filter_column].dropna().unique())\n",
        "#     else:  # Numerical column\n",
        "#         filter_ops = random.choice(numerical_ops)\n",
        "#         filter_value = random.choice(df[filter_column].dropna().unique())\n",
        "\n",
        "#     # Generate a random target column\n",
        "#     target_column = random.choice(\n",
        "#         [\n",
        "#             col\n",
        "#             for col in [*categorical_columns, *numerical_columns]\n",
        "#             if col != filter_column\n",
        "#         ]\n",
        "#     )\n",
        "\n",
        "#     if target_column in categorical_columns:\n",
        "#         target_value = random.choice(df[target_column].dropna().unique())\n",
        "\n",
        "#         if target_column == \"Survived\":\n",
        "#             target_value = \"survived\" if target_value == 1 else \"not survived\"\n",
        "#         elif target_column == \"Pclass\":\n",
        "#             target_value = f\"are in class {target_value}\"\n",
        "#         elif target_column == \"Embarked\":\n",
        "#             target_value = f\"embarked in {target_value}\"\n",
        "#         elif target_column == \"Sex\":\n",
        "#             target_value = f\"are {target_value}\"\n",
        "#     else:\n",
        "#         target_ops = random.choice(numerical_ops)\n",
        "#         target_value = random.choice(df[target_column].dropna().unique())\n",
        "\n",
        "#     # Create a question template that take a target column, a filter column and a filter value\n",
        "#     # Compute the correct answer for the given target column, filter column and filter value\n",
        "#     if filter_column in categorical_columns and target_column in categorical_columns:\n",
        "#         question = (\n",
        "#             f\"How many passengers {target_value} and {filter_column} is {filter_value}?\"\n",
        "#         )\n",
        "#         correct_answer = df[\n",
        "#             (df[filter_column] == filter_value) & (df[target_column] == target_value)\n",
        "#         ][target_column].count()\n",
        "#     elif filter_column in numerical_columns and target_column in categorical_columns:\n",
        "#         question = f\"How many passengers {target_value} and {filter_column} {filter_ops} {filter_value}?\"\n",
        "#         correct_answer = df[\n",
        "#             operators[filter_ops](df[filter_column], filter_value)\n",
        "#             & (df[target_column] == target_value)\n",
        "#         ][target_column].count()\n",
        "#     elif filter_column in categorical_columns and target_column in numerical_columns:\n",
        "#         question = f\"How many passengers {target_column} {target_ops} {target_value} and {filter_column} is {filter_value}?\"\n",
        "#         correct_answer = df[\n",
        "#             operators[target_ops](df[target_column], target_value)\n",
        "#             & (df[filter_column] == filter_value)\n",
        "#         ][target_column].count()\n",
        "#     else:\n",
        "#         question = f\"How many passengers {target_column} {target_ops} {target_value} and {filter_column} {filter_ops} {filter_value}?\"\n",
        "#         correct_answer = df[\n",
        "#             operators[target_ops](df[target_column], target_value)\n",
        "#             & operators[filter_ops](df[filter_column], filter_value)\n",
        "#         ][target_column].count()\n",
        "\n",
        "#     # return formatted question and associated answer in a dict {\"question\":[question], \"answer\":[answer]}\n",
        "#     return {\"question\": question, \"answer\": correct_answer}\n",
        "\n",
        "\n",
        "# generate_random_question(generate_filter_question, df, k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzDJ9c3VhHt2"
      },
      "source": [
        "## 1.4 Guided Introduction: The Evaluation.\n",
        "\n",
        "The last step in this section is to evaluate our model on 20 random questions! We'll use simple accuracy.\n",
        "\n",
        "You should have an accuracy between 0.9 and 1.\n",
        "\n",
        "<font color='red'>TODO: Follow instruction in comment of the cell below.</font>\n",
        "\n",
        "<font color='green'>BONUS: Investigate on errors and improve our prompt/parsing to solve them.</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "xiE53oszRGcq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating random questions\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [01:11<00:00,  3.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting the evaluation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 14/20 [01:16<00:31,  5.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output is a DataFrame or Series, please return a scalar.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 18/20 [01:38<00:10,  5.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output is a DataFrame or Series, please return a scalar.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [01:48<00:00,  5.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate 20 random question\n",
        "print(\"Generating random questions\")\n",
        "questions = generate_random_question(generate_filter_question, df, k=20)\n",
        "sum_correct = 0\n",
        "incorrect_answers = []\n",
        "\n",
        "# Iterate over question to format prompt, generate answer and execute answer.\n",
        "print(\"\\nStarting the evaluation\")\n",
        "for q in tqdm(questions):\n",
        "    prompt = example_prompt_template.format(\n",
        "        var_name=\"df\",\n",
        "        df_info=df.head(5).to_string(index=False),\n",
        "        user_question=q[\"question\"],\n",
        "    )\n",
        "    answer = generate_answer(prompt)\n",
        "    res = exec_answer(answer, q[\"answer\"])\n",
        "    if res == False:\n",
        "        incorrect_answers.append((q, answer))\n",
        "\n",
        "    sum_correct += res\n",
        "\n",
        "# Report the Accuracy\n",
        "print(f\"Accuracy: {sum_correct}/{len(questions)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incorrect answers: [({'question': \"How many rows in the dataset have the value 'Q' in the 'Embarked' column and the value '64.0' in the 'Age' column?\", 'answer': 0}, \"Python code:\\n```python\\n# Count the number of rows where 'Embarked' is 'Q' and 'Age' is '64.0'\\noutput = (df['Embarked'] == 'Q') & (df['Age'] == 64.0).sum()\\nprint(output)\\n```\"), ({'question': \"How many rows in the dataset have the value 'C' in the 'Embarked' column and the value '1' in the 'Pclass' column?\", 'answer': 74}, \"Python code:\\n```python\\n# Count the number of rows where 'Embarked' is 'C' and 'Pclass' is '1'\\noutput = (df['Embarked'] == 'C') & (df['Pclass'] == 1).sum()\\nprint(output)\\n```\")]\n"
          ]
        }
      ],
      "source": [
        "print(\"Incorrect answers:\", incorrect_answers)\n",
        "\n",
        "# WRITE THAT OUR ERRORS ARE DUE TO THE FACT THAT THE OUTPUT IS A DATAFRAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGYL5LUeiEBI"
      },
      "source": [
        "## 2. More Questions.\n",
        "\n",
        "Now it's your turn to imagine a type of question (\"How many ...\"). Implement a function to generate new type of question. Verify that our previous code work with your new question then evaluate it.\n",
        "\n",
        "<font color='red'>TODO: Generate **AT LEAST ONE** new type of question and report this new question accuracy.</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def generate_fare_question(df):\n",
        "    # Create a question template that take a target column, a filter column and a filter value\n",
        "    template = (\n",
        "        \"Generate a question based on this tabular dataset:\\n\"\n",
        "        \"{df_info}\\n\"\n",
        "        \"The question should be about the total fare for the passengers where \"\n",
        "        \"the value in the column '{filter_col}' is '{filter_val}'.\"\n",
        "        \"Here are some examples of questions:\"\n",
        "        \"1) What is the total fare for the passengers who are in class 3?\"\n",
        "        \"2) How much did the passengers who embarked in S pay in total?\"\n",
        "        \"3) What is the total fare for male passengers?\"\n",
        "    )\n",
        "\n",
        "    # Get a random target column and a random filter column (be careful they should be different)\n",
        "    # Get a random filter value inside the filer column. Avoid NaN values.\n",
        "    filter_col = random.choice([col for col in df.columns if col != \"Fare\"])\n",
        "    filter_val = random.choice(df[filter_col].dropna().unique())\n",
        "\n",
        "    content = template.format(\n",
        "        df_info=df.head(5).to_string(index=False),\n",
        "        filter_col=filter_col,\n",
        "        filter_val=filter_val,\n",
        "    )\n",
        "\n",
        "    chat = [\n",
        "        {\"role\": \"user\", \"content\": content},\n",
        "    ]\n",
        "    chat_encoded = tokenizer.apply_chat_template(chat, return_tensors=\"pt\").to(\n",
        "        llm.device\n",
        "    )\n",
        "\n",
        "    llm_outputs_ids = llm.generate(\n",
        "        input_ids=chat_encoded,\n",
        "        generation_config=generation_config,\n",
        "    )[0]\n",
        "    question = tokenizer.decode(\n",
        "        llm_outputs_ids[chat_encoded.size(1) :], skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    # Compute the correct answer for the given target column, filter column and filter value.\n",
        "    correct_answer = df[df[filter_col] == filter_val][\"Fare\"].sum()\n",
        "\n",
        "    # return formatted question and associated answer in a dict {\"question\":[question], \"answer\":[answer]}\n",
        "    return {\"question\": question, \"answer\": correct_answer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating random questions\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 1/20 [00:02<00:48,  2.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Survived' is '0'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 2/20 [00:04<00:37,  2.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare paid by male passengers?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 3/20 [00:07<00:41,  2.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Name' is 'Hale, Mr. Reginald'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 4/20 [00:09<00:40,  2.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Survived' is '0'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 5/20 [00:11<00:35,  2.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers who embarked in 'C'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 6/20 [00:14<00:34,  2.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'PassengerId' is '40'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 7/20 [00:17<00:32,  2.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Survived' is '0'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 8/20 [00:20<00:31,  2.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Name' is 'Bourke, Mrs. John (Catherine)'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 9/20 [00:22<00:27,  2.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers who embarked in 'S'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 10/20 [00:24<00:25,  2.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Ticket' is '345774'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 11/20 [00:27<00:23,  2.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Ticket' is '350036'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 12/20 [00:31<00:22,  2.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Name' is 'Thayer, Mrs. John Borland (Marian Longstreth Morris)'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 13/20 [00:33<00:18,  2.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers who embarked in 'C'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 14/20 [00:35<00:15,  2.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'PassengerId' is '207'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 15/20 [00:38<00:13,  2.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'SibSp' is '3'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 16/20 [00:40<00:09,  2.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare paid by male passengers?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 17/20 [00:43<00:07,  2.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Name' is 'Louch, Mrs. Charles Alexander (Alice Adelaide Slow)'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 18/20 [00:45<00:05,  2.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Survived' is '0'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 19/20 [00:48<00:02,  2.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'SibSp' is '1'?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:51<00:00,  2.56s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the total fare for the passengers where the value in the column 'Age' is '71.0'?\n",
            "\n",
            "Starting the evaluation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [01:55<00:00,  5.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate 20 random question\n",
        "print(\"Generating random questions\")\n",
        "questions = generate_random_question(generate_fare_question, df, k=20)\n",
        "sum_correct = 0\n",
        "incorrect_answers = []\n",
        "\n",
        "# Iterate over question to format prompt, generate answer and execute answer.\n",
        "print(\"\\nStarting the evaluation\")\n",
        "for q in tqdm(questions):\n",
        "    prompt = example_prompt_template.format(\n",
        "        var_name=\"df\",\n",
        "        df_info=df.head(5).to_string(index=False),\n",
        "        user_question=q[\"question\"],\n",
        "    )\n",
        "    answer = generate_answer(prompt)\n",
        "    res = exec_answer(answer, q[\"answer\"])\n",
        "    if res == False:\n",
        "        incorrect_answers.append((prompt, answer))\n",
        "\n",
        "    sum_correct += res\n",
        "\n",
        "# Report the Accuracy\n",
        "print(f\"Accuracy: {sum_correct}/{len(questions)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt35rcuMoAdW"
      },
      "source": [
        "## 3. More datasets.\n",
        "\n",
        "Below we load a new dataset: \"adult_income_dataset\".\n",
        "\n",
        "<font color='red'>TODO: Evaluate our questions on this new dataset. Report the accuracy. Comment Any differences.</font>\n",
        "\n",
        "<font color='green'>BONUS: Try to find a prompt that answer this question: What is the mean salary of titanic surviror based on adult dataset.</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "z33vyj_Sk_WX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48842 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   age              48842 non-null  int64 \n",
            " 1   workclass        48842 non-null  object\n",
            " 2   fnlwgt           48842 non-null  int64 \n",
            " 3   education        48842 non-null  object\n",
            " 4   educational-num  48842 non-null  int64 \n",
            " 5   marital-status   48842 non-null  object\n",
            " 6   occupation       48842 non-null  object\n",
            " 7   relationship     48842 non-null  object\n",
            " 8   race             48842 non-null  object\n",
            " 9   gender           48842 non-null  object\n",
            " 10  capital-gain     48842 non-null  int64 \n",
            " 11  capital-loss     48842 non-null  int64 \n",
            " 12  hours-per-week   48842 non-null  int64 \n",
            " 13  native-country   48842 non-null  object\n",
            " 14  income           48842 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 5.6+ MB\n"
          ]
        }
      ],
      "source": [
        "adult = pd.read_csv(\"hf://datasets/meghana/adult_income_dataset/adult.csv\")\n",
        "adult.info()\n",
        "\n",
        "titanic = df"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
